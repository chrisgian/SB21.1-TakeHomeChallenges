{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: \n",
    "- Extract Reviews and Category Content for Each Product Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Modules, Read Raw Reviews, Check Count of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of lines 15010574\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "\n",
    "raw_reviews = open(\"amazon-meta.txt\",encoding=\"utf8\")\n",
    "raw_reviews = raw_reviews.readlines()\n",
    "print(\"Number of lines\", len(raw_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class extract:\n",
    "    def __init__(self, N = None):\n",
    "        if N == None:\n",
    "            self.content = open(\"amazon-meta.txt\",encoding=\"utf8\")\n",
    "        else: \n",
    "            self.content = open(\"amazon-meta.txt\",encoding=\"utf8\")\n",
    "            self.content = list(islice(self.content, N))\n",
    "       \n",
    "        self.indexed_content= enumerate(self.content, 1)\n",
    "\n",
    "    def find(self,search_by, columns = None):\n",
    "        self.line_content = []\n",
    "        self.line_location = []\n",
    "        \n",
    "        for num, line in self.indexed_content:\n",
    "            if re.match(search_by, np.str.strip(line)) is None:\n",
    "                pass\n",
    "            else:\n",
    "                self.line_location.append(num)\n",
    "                self.line_content.append(line)\n",
    "                \n",
    "        if columns == None:\n",
    "            self.extracted_content = [np.str.split(np.str.strip(i)) for i in self.line_content] # Keep these as strings so can look into during debug\n",
    "        else:\n",
    "            self.extracted_content = [[np.str.split(np.str.strip(i))[column] for column in columns] for i in self.line_content] # Keep these as strings so can look into\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_extraction = extract()\n",
    "id_extraction.find(\"^Id:\")\n",
    "\n",
    "review_extraction = extract()\n",
    "review_extraction.find(\"^reviews:\")\n",
    "\n",
    "category_extraction = extract()\n",
    "category_extraction.find(\"^categories:\")\n",
    "\n",
    "df_id_locations = pd.DataFrame({\"start\":id_extraction.line_location,\"ID\":[int(i[1]) for i in id_extraction.extracted_content]})\n",
    "df_id_locations['end'] = df_id_locations.start.shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_group = extract()\n",
    "extract_group.find('group:')\n",
    "\n",
    "extract_rank = extract()\n",
    "extract_rank.find('salesrank:')\n",
    "\n",
    "extract_sim = extract()\n",
    "extract_sim.find('similar:')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Index of Content Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EXTRACT CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = extract()\n",
    "file = [i for i in file.content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = df_id_locations.apply(tuple, axis=1)\n",
    "chunks = []\n",
    "for i in rows:\n",
    "    c,a,b = i\n",
    "    chunks.append([c]+[file[int(i)] for i in np.arange(a-1,b-2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "expandedrange = []\n",
    "for i in df_id_locations.iterrows():    \n",
    "    prod_id = i[1][0]\n",
    "    row_range = np.arange(i[1][1], i[1][2])\n",
    "    length = len(row_range)\n",
    "    ids += [prod_id]*length\n",
    "    expandedrange += list(row_range)\n",
    "df_id_row_lookup = pd.DataFrame(list(zip(ids,expandedrange)), columns = ['ID', 'Rows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. IDENTIFY REVIEW / CATEGORY MATCH in RANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_id_row_lookup['review_start'] = df_id_row_lookup.Rows.isin(review_extraction.line_location) + 0\n",
    "df_id_row_lookup['category_start'] = df_id_row_lookup.Rows.isin(category_extraction.line_location) + 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_id_row_lookup['group_start'] = df_id_row_lookup.Rows.isin(extract_group.line_location) + 0 \n",
    "df_id_row_lookup['rank_start'] = df_id_row_lookup.Rows.isin(extract_rank.line_location) + 0 \n",
    "df_id_row_lookup['sim_start'] = df_id_row_lookup.Rows.isin(extract_sim.line_location) + 0 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  JOIN RANGE TO REVIEW / CAT LOCATION. BUILD DF AND JOIN TO Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detail_index = df_id_row_lookup\n",
    "detail_index = pd.melt(detail_index, id_vars= ['ID','Rows'])\n",
    "detail_index = detail_index.query(\"value != 0\")\n",
    "detail_index = pd.pivot_table(index = [\"ID\"], columns = 'variable', values='Rows', data = detail_index)\n",
    "df_id_locations = df_id_locations.merge(detail_index, left_on= \"ID\", right_index= True, how = 'right')\n",
    "df_chunk_lengths = pd.DataFrame([[i[0], len(i)] for i in chunks], columns = [\"ID\", \"CHUNK_LEN\"])\n",
    "df_id_locations = df_id_locations.merge(df_chunk_lengths, on = \"ID\", how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create and write id tables for rank, group, and similiarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>category_start</th>\n",
       "      <th>group_start</th>\n",
       "      <th>rank_start</th>\n",
       "      <th>review_start</th>\n",
       "      <th>sim_start</th>\n",
       "      <th>CHUNK_LEN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>44.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>55.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>55</td>\n",
       "      <td>70.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>81.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID  start   end  category_start  group_start  rank_start  review_start  \\\n",
       "0  1      8  21.0            14.0         11.0        12.0          17.0   \n",
       "1  2     21  44.0            27.0         24.0        25.0          30.0   \n",
       "2  3     44  55.0            50.0         47.0        48.0          52.0   \n",
       "3  4     55  70.0            61.0         58.0        59.0          67.0   \n",
       "4  5     70  81.0            76.0         73.0        74.0          79.0   \n",
       "\n",
       "   sim_start  CHUNK_LEN  \n",
       "0       13.0         13  \n",
       "1       26.0         23  \n",
       "2       49.0         11  \n",
       "3       60.0         15  \n",
       "4       75.0         11  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_id_locations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_class = [np.str.split(np.str.strip(i))[1] for i in extract_group.line_content]\n",
    "df_groups = pd.DataFrame(list(zip(extract_group.line_location,group_class)), columns = ['group_start','group'])\n",
    "df_groups = df_groups.merge(df_id_locations[['ID','group_start']], how = 'inner')\n",
    "\n",
    "rank_value = [np.str.split(np.str.strip(i))[1] for i in extract_rank.line_content]\n",
    "df_rank = pd.DataFrame(list(zip(extract_rank.line_location,rank_value)), columns = ['rank_start','rank'])\n",
    "df_rank = df_rank.merge(df_id_locations[['ID','rank_start']], how = 'inner')\n",
    "df_rank_and_group = df_rank.merge(df_groups, on = 'ID').drop(['group_start','rank_start'],1)\n",
    "df_rank_and_group.to_csv(\"rank_and_group.csv\")\n",
    "\n",
    "sim_items = [np.str.split(np.str.strip(i)) for i in extract_sim.line_content]\n",
    "df_similar = pd.DataFrame(sim_items)\n",
    "df_similar['sim_start'] = extract_sim.line_location\n",
    "df_similar = pd.melt(id_vars = 'sim_start',frame= df_similar.iloc[:,2:])\n",
    "df_similar = df_similar.merge(df_id_locations[['ID','sim_start']], how = 'inner').dropna()\n",
    "df_similar.to_csv('similar.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Content Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_detail_rows(columns, dont_split = True):\n",
    "    within_lines = df_id_locations[columns].apply(tuple, axis=1)\n",
    "    detail_collector = []\n",
    "    for row in within_lines:\n",
    "        prod_id,a,b = row\n",
    "\n",
    "        if (b == a):\n",
    "            review_detail_collector.append([[int(prod_id)] + [np.nan]*5])\n",
    "\n",
    "        prod_id = int(prod_id)\n",
    "        search_space = chunks[prod_id]\n",
    "        query_range = np.arange(a,b-2)\n",
    "        \n",
    "        if dont_split == True:\n",
    "            detail_collector += [[prod_id, file[int(line)]] for line in query_range]\n",
    "        else: \n",
    "            detail_collector += [[prod_id] + np.str.split(file[int(line)]) for line in query_range]\n",
    "    return detail_collector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract / Create Reviews FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_frame = extract_detail_rows(columns =  ['ID','review_start', 'end'], dont_split= False)\n",
    "reviews_frame = pd.DataFrame(reviews_frame)\n",
    "reviews_frame = reviews_frame.drop([2,4,6,8], axis = 1)\n",
    "reviews_frame.columns = ['PROD_ID','REVIEW_DATE','CUSTOMER_ID','RATING','VOTES','HELPFUL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract / Create CATEGORY FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = extract_detail_rows(columns =  ['ID','category_start', 'review_start'], dont_split= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse / Organize categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "all_categories = []\n",
    "for case in categories:\n",
    "    prod_id = case[0]\n",
    "    counter += 1\n",
    "    category_content = case[1]\n",
    "    category_content = np.str.strip(category_content)\n",
    "    category_content = re.sub(r\"^[|]|[]]\", \"\", category_content)\n",
    "    category_content = category_content.split(\"|\")\n",
    "    sub_count = 0 \n",
    "    for sub_case in category_content:\n",
    "        sub_count += 1\n",
    "        all_categories += [[prod_id] + [counter] + [sub_count] +  sub_case.split(\"[\")]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Chris\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "category_frame = pd.DataFrame(all_categories, columns = ['PROD_ID', 'TBL_ID','CATEGORY_ORDER','DESC','CAT_CODE','X'])\n",
    "category_frame1 = category_frame[category_frame.X.isnull()].drop(\"X\",1)\n",
    "category_frame2 = category_frame[~category_frame.X.isnull()]\n",
    "category_frame2['DESC'] = category_frame2.DESC.str.strip() + \" (\" + category_frame2.CAT_CODE.str.strip()+\")\"\n",
    "category_frame2['CAT_CODE'] = category_frame2.X\n",
    "category_frame2 = category_frame2.drop(\"X\",1)\n",
    "category_frame = category_frame1.append(category_frame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_frame.to_csv(\"categories.csv\")\n",
    "reviews_frame.to_csv(\"reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
