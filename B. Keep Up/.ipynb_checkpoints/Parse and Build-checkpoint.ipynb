{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: \n",
    "- Extract Reviews and Category Content for Each Product Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load Modules, Read Raw Reviews, Check Count of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from itertools import islice\n",
    "\n",
    "raw_reviews = open(\"amazon-meta.txt\",encoding=\"utf8\")\n",
    "raw_reviews = raw_reviews.readlines()\n",
    "print(\"Number of lines\", len(raw_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class extract:\n",
    "    def __init__(self, N = None):\n",
    "        if N == None:\n",
    "            self.content = open(\"amazon-meta.txt\",encoding=\"utf8\")\n",
    "        else: \n",
    "            self.content = open(\"amazon-meta.txt\",encoding=\"utf8\")\n",
    "            self.content = list(islice(self.content, N))\n",
    "       \n",
    "        self.indexed_content= enumerate(self.content, 1)\n",
    "\n",
    "    def find(self,search_by, columns = None):\n",
    "        self.line_content = []\n",
    "        self.line_location = []\n",
    "        \n",
    "        for num, line in self.indexed_content:\n",
    "            if re.match(search_by, np.str.strip(line)) is None:\n",
    "                pass\n",
    "            else:\n",
    "                self.line_location.append(num)\n",
    "                self.line_content.append(line)\n",
    "                \n",
    "        if columns == None:\n",
    "            self.extracted_content = [np.str.split(np.str.strip(i)) for i in self.line_content] # Keep these as strings so can look into during debug\n",
    "        else:\n",
    "            self.extracted_content = [[np.str.split(np.str.strip(i))[column] for column in columns] for i in self.line_content] # Keep these as strings so can look into\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_extraction = extract()\n",
    "id_extraction.find(\"^Id:\")\n",
    "\n",
    "review_extraction = extract()\n",
    "review_extraction.find(\"^reviews:\")\n",
    "\n",
    "category_extraction = extract()\n",
    "category_extraction.find(\"^categories:\")\n",
    "\n",
    "df_id_locations = pd.DataFrame({\"start\":id_extraction.line_location,\"ID\":[int(i[1]) for i in id_extraction.extracted_content]})\n",
    "df_id_locations['end'] = df_id_locations.start.shift(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Index of Content Location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EXTRACT CHUNKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = extract()\n",
    "file = [i for i in file.content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = df_id_locations.apply(tuple, axis=1)\n",
    "chunks = []\n",
    "for i in rows:\n",
    "    c,a,b = i\n",
    "    chunks.append([c]+[file[int(i)] for i in np.arange(a-1,b-2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Build Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = []\n",
    "expandedrange = []\n",
    "for i in df_id_locations.iterrows():    \n",
    "    prod_id = i[1][0]\n",
    "    row_range = np.arange(i[1][1], i[1][2])\n",
    "    length = len(row_range)\n",
    "    ids += [prod_id]*length\n",
    "    expandedrange += list(row_range)\n",
    "df_id_row_lookup = pd.DataFrame(list(zip(ids,expandedrange)), columns = ['ID', 'Rows'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. IDENTIFY REVIEW / CATEGORY MATCH in RANGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_id_row_lookup['review_start'] = df_id_row_lookup.Rows.isin(review_extraction.line_location) + 0\n",
    "df_id_row_lookup['category_start'] = df_id_row_lookup.Rows.isin(category_extraction.line_location) + 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.  JOIN RANGE TO REVIEW / CAT LOCATION. BUILD DF AND JOIN TO Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detail_index = df_id_row_lookup\n",
    "detail_index = pd.melt(detail_index, id_vars= ['ID','Rows'])\n",
    "detail_index = detail_index.query(\"value != 0\")\n",
    "detail_index = pd.pivot_table(index = [\"ID\"], columns = 'variable', values='Rows', data = detail_index)\n",
    "df_id_locations = df_id_locations.merge(detail_index, left_on= \"ID\", right_index= True, how = 'right')\n",
    "df_chunk_lengths = pd.DataFrame([[i[0], len(i)] for i in chunks], columns = [\"ID\", \"CHUNK_LEN\"])\n",
    "df_id_locations = df_id_locations.merge(df_chunk_lengths, on = \"ID\", how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Content Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_detail_rows(columns, dont_split = True):\n",
    "    within_lines = df_id_locations[columns].apply(tuple, axis=1)\n",
    "    detail_collector = []\n",
    "    for row in within_lines:\n",
    "        prod_id,a,b = row\n",
    "\n",
    "        if (b == a):\n",
    "            review_detail_collector.append([[int(prod_id)] + [np.nan]*5])\n",
    "\n",
    "        prod_id = int(prod_id)\n",
    "        search_space = chunks[prod_id]\n",
    "        query_range = np.arange(a,b-2)\n",
    "        \n",
    "        if dont_split == True:\n",
    "            detail_collector += [[prod_id, file[int(line)]] for line in query_range]\n",
    "        else: \n",
    "            detail_collector += [[prod_id] + np.str.split(file[int(line)]) for line in query_range]\n",
    "    return detail_collector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract / Create Reviews FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews_frame = extract_detail_rows(columns =  ['ID','review_start', 'end'], dont_split= False)\n",
    "reviews_frame = pd.DataFrame(reviews_frame)\n",
    "reviews_frame = reviews_frame.drop([2,4,6,8], axis = 1)\n",
    "reviews_frame.columns = ['PROD_ID','REVIEW_DATE','CUSTOMER_ID','RATING','VOTES','HELPFUL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract / Create CATEGORY FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = extract_detail_rows(columns =  ['ID','category_start', 'review_start'], dont_split= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse / Organize categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "all_categories = []\n",
    "for case in categories:\n",
    "    prod_id = case[0]\n",
    "    counter += 1\n",
    "    category_content = case[1]\n",
    "    category_content = np.str.strip(category_content)\n",
    "    category_content = re.sub(r\"^[|]|[]]\", \"\", category_content)\n",
    "    category_content = category_content.split(\"|\")\n",
    "    sub_count = 0 \n",
    "    for sub_case in category_content:\n",
    "        sub_count += 1\n",
    "        all_categories += [[prod_id] + [counter] + [sub_count] +  sub_case.split(\"[\")]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_frame = pd.DataFrame(all_categories, columns = ['PROD_ID', 'TBL_ID','CATEGORY_ORDER','DESC','CAT_CODE','X'])\n",
    "category_frame1 = category_frame[category_frame.X.isnull()].drop(\"X\",1)\n",
    "category_frame2 = category_frame[~category_frame.X.isnull()]\n",
    "category_frame2['DESC'] = category_frame2.DESC.str.strip() + \" (\" + category_frame2.CAT_CODE.str.strip()+\")\"\n",
    "category_frame2['CAT_CODE'] = category_frame2.X\n",
    "category_frame2 = category_frame2.drop(\"X\",1)\n",
    "category_frame = category_frame1.append(category_frame2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITE TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_frame.to_csv(\"categories.csv\")\n",
    "reviews_frame.to_csv(\"reviews.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
